{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e699cd97-25db-45e4-bb01-6f00fa520ff2",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029de8f-7fce-45d0-8d4e-53433f8661e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager() \n",
    "conf = fablib.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46cb8a3-d55e-4a9a-add2-0c3907f101ac",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8fa5ac-e3e4-47f5-987e-bb42ed21d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name=\"l4s-new\" + fablib.get_bastion_username()\n",
    "\n",
    "node_conf = [\n",
    " {'name': \"tx_L4S\",    'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}, \n",
    " {'name': \"tx_legacy\",    'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}, \n",
    " {'name': \"router\", 'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}, \n",
    " {'name': \"delay\", 'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}, \n",
    " {'name': \"rx_L4S\",    'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}, \n",
    " {'name': \"rx_legacy\",    'cores': 4, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}\n",
    "]\n",
    "net_conf = [\n",
    " {\"name\": \"net-tx\", \"subnet\": \"10.0.0.0/24\", \"nodes\": [{\"name\": \"tx_L4S\",   \"addr\": \"10.0.0.100\"}, {\"name\": \"tx_legacy\",   \"addr\": \"10.0.0.101\"}, {\"name\": \"delay\", \"addr\": \"10.0.0.2\"}]},\n",
    " {\"name\": \"net-delay-router\", \"subnet\": \"10.0.2.0/24\", \"nodes\": [{\"name\": \"delay\",   \"addr\": \"10.0.2.2\"}, {\"name\": \"router\", \"addr\": \"10.0.2.1\"}]},\n",
    " {\"name\": \"net-rx\", \"subnet\": \"10.0.5.0/24\", \"nodes\": [{\"name\": \"router\",   \"addr\": \"10.0.5.1\"}, {\"name\": \"rx_L4S\", \"addr\": \"10.0.5.100\"}, {\"name\": \"rx_legacy\", \"addr\": \"10.0.5.101\"}]}\n",
    "\n",
    "]\n",
    "route_conf = [\n",
    " {\"addr\": \"10.0.5.0/24\", \"gw\": \"10.0.0.2\", \"nodes\": [\"tx_L4S\", \"tx_legacy\"]}, \n",
    " {\"addr\": \"10.0.5.0/24\", \"gw\": \"10.0.2.1\", \"nodes\": [\"delay\"]},\n",
    "\n",
    " {\"addr\": \"10.0.0.0/24\", \"gw\": \"10.0.5.1\", \"nodes\": [\"rx_L4S\", \"rx_legacy\"]},\n",
    " {\"addr\": \"10.0.0.0/24\", \"gw\": \"10.0.2.2\", \"nodes\": [\"router\"]}\n",
    "\n",
    "]\n",
    "exp_conf = {'cores': sum([ n['cores'] for n in node_conf]), 'nic': sum([len(n['nodes']) for n in net_conf]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671606b1-5114-4ed2-a45d-2aedb9715d51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reserve resources\n",
    "\n",
    "Now, we are ready to reserve resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18d7f0-b22f-4f51-959d-1625d8975731",
   "metadata": {},
   "source": [
    "First, make sure you don’t already have a slice with this name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c6a12-8ef0-41c2-95c1-a0d6992c696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slice = fablib.get_slice(slice_name)\n",
    "    print(\"You already have a slice by this name!\")\n",
    "    print(\"If you previously reserved resources, skip to the 'log in to resources' section.\")\n",
    "except:\n",
    "    print(\"You don't have a slice named %s yet.\" % slice_name)\n",
    "    print(\"Continue to the next step to make one.\")\n",
    "    slice = fablib.new_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ba302-135e-4801-b1e0-9494ce668fce",
   "metadata": {},
   "source": [
    "We will select a random site that has sufficient resources for our experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973c997-62d8-452d-9022-864b8dc822c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    site_name = fablib.get_random_site()\n",
    "    if ( (fablib.resources.get_core_available(site_name) > 1.2*exp_conf['cores']) and\n",
    "        (fablib.resources.get_component_available(site_name, 'SharedNIC-ConnectX-6') > 1.2**exp_conf['nic']) ):\n",
    "        break\n",
    "\n",
    "fablib.show_site(site_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6010c4-245b-4589-b827-5a0ac31b728a",
   "metadata": {},
   "source": [
    "Then we will add hosts and network segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ef98c-0a2d-4ed6-b7f3-0adbf4ae1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the nodes\n",
    "for n in node_conf:\n",
    "    slice.add_node(name=n['name'], site=site_name, \n",
    "                   cores=n['cores'], \n",
    "                   ram=n['ram'], \n",
    "                   disk=n['disk'], \n",
    "                   image=n['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2f24e-06dd-4f45-8a0f-3ca287821f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the network segments\n",
    "for n in net_conf:\n",
    "    ifaces = [slice.get_node(node[\"name\"]).add_component(model=\"NIC_Basic\", \n",
    "                                                 name=n[\"name\"]).get_interfaces()[0] for node in n['nodes'] ]\n",
    "    slice.add_l2network(name=n[\"name\"], type='L2Bridge', interfaces=ifaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98e9c9-fcd8-45bd-bafe-9cfadfd369a6",
   "metadata": {},
   "source": [
    "The following cell submits our request to the FABRIC site. The output of this cell will update automatically as the status of our request changes.\n",
    "\n",
    "-   While it is being prepared, the “State” of the slice will appear as “Configuring”.\n",
    "-   When it is ready, the “State” of the slice will change to “StableOK”.\n",
    "\n",
    "You may prefer to walk away and come back in a few minutes (for simple slices) or a few tens of minutes (for more complicated slices with many resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad95a3c-fd11-475c-94b1-cf1587666663",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415d743-5ee5-4029-ab5e-1391d645c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_state()\n",
    "slice.wait_ssh(progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b617c-2e5c-40c3-98fc-73be3183b5f4",
   "metadata": {},
   "source": [
    "### Extend your slice\n",
    "\n",
    "If you don’t plan to finish an experiment in one day, you can extend your slice. The following cell extends your reservation for 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4b068-005a-4fbf-ad31-89dccc85dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end date to 7 days from now\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=7)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "slice.renew(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ac5bb-61a3-423f-a549-7df87336f1cf",
   "metadata": {},
   "source": [
    "### Configure Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14183601-68ff-4baa-8145-94b1ad78cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in slice.get_nodes():\n",
    "    # Download and unzip the kernel package\n",
    "    node.execute(\"wget https://github.com/L4STeam/linux/releases/download/testing-build/l4s-testing.zip\")\n",
    "    node.execute(\"sudo apt install unzip\")\n",
    "    node.execute(\"unzip l4s-testing.zip\")\n",
    "    \n",
    "    # Install the kernel packages and update GRUB\n",
    "    node.execute(\"sudo dpkg --install debian_build/*\")\n",
    "    node.execute(\"sudo update-grub\")\n",
    "    node.execute(\"sudo reboot\")\n",
    "\n",
    "# wait for all nodes to come back up\n",
    "slice.wait_ssh(progress=True)\n",
    "for node in slice.get_nodes():\n",
    "    # check kernel version\n",
    "    node.execute(\"hostname; uname -a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910fe90-6c02-49ca-9461-72a9c0494b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration for DUALPI2 bottleneck\n",
    "cmd_dualpi2=\"\"\"sudo apt-get update\n",
    "sudo apt -y install git gcc make bison flex libdb-dev libelf-dev pkg-config libbpf-dev libmnl-dev libcap-dev libatm1-dev selinux-utils libselinux1-dev\n",
    "sudo git clone https://github.com/L4STeam/iproute2.git && cd iproute2\n",
    "sudo ./configure\n",
    "sudo make\n",
    "sudo make install\"\"\"\n",
    "slice.get_node(name=\"router\").execute(cmd_dualpi2)\n",
    "slice.get_node(name=\"router\").execute(\"sudo modprobe sch_dualpi2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24abb79-8cf0-4175-a405-56265ccf0538",
   "metadata": {},
   "source": [
    "### Configure resources\n",
    "\n",
    "Next, we will configure the resources so they are ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddebb2cd-42fb-48d5-962b-11f30e68f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f6d80-3d38-4943-9c1a-60d92c3d0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "# this will take a while and will run in background while you do other steps\n",
    "for n in node_conf:\n",
    "    if len(n['packages']):\n",
    "        node = slice.get_node(n['name'])\n",
    "        pkg = \" \".join(n['packages'])\n",
    "        node.execute_thread(\"sudo apt update; sudo apt -y install %s\" % pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96e4be-1a50-4a6f-b579-9fcb1ffd843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring interfaces up and either assign an address (if there is one) or flush address\n",
    "from ipaddress import ip_address, IPv4Address, IPv4Network\n",
    "\n",
    "for net in net_conf:\n",
    "    for n in net['nodes']:\n",
    "        if_name = n['name'] + '-' + net['name'] + '-p1'\n",
    "        iface = slice.get_interface(if_name)\n",
    "        iface.ip_link_up()\n",
    "        if n['addr']:\n",
    "            iface.ip_addr_add(addr=n['addr'], subnet=IPv4Network(net['subnet']))\n",
    "        else:\n",
    "            iface.get_node().execute(\"sudo ip addr flush dev %s\"  % iface.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bcf2bf-b8ec-4be8-8be8-09cdc19259d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a \"hosts\" file that has names and addresses of every node\n",
    "hosts_txt = [ \"%s\\t%s\" % ( n['addr'], n['name'] ) for net in net_conf  for n in net['nodes'] if type(n) is dict and n['addr']]\n",
    "for n in slice.get_nodes():\n",
    "    for h in hosts_txt:\n",
    "        n.execute(\"echo %s | sudo tee -a /etc/hosts\" % h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04674abd-afec-4f16-9513-9ae81b4cfca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable IPv4 forwarding on all nodes\n",
    "for n in slice.get_nodes():\n",
    "    n.execute(\"sudo sysctl -w net.ipv4.ip_forward=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd32e9b-0ad6-48ec-b7a3-95380bd73862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up static routes\n",
    "for rt in route_conf:\n",
    "    for n in rt['nodes']:\n",
    "        slice.get_node(name=n).ip_route_add(subnet=IPv4Network(rt['addr']), gateway=rt['gw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507e702-bc51-40af-a4b3-a6a015db40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off segmentation offload on interfaces\n",
    "for iface in slice.get_interfaces():\n",
    "    iface_name = iface.get_device_name()\n",
    "    n = iface.get_node()\n",
    "    offloads = [\"gro\", \"lro\", \"gso\", \"tso\"]\n",
    "    for offload in offloads:\n",
    "        n.execute(\"sudo ethtool -K %s %s off\" % (iface_name, offload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03518528-84bc-4eed-a9b0-33ef803ce901",
   "metadata": {},
   "source": [
    "### Draw the network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486469db-835d-4fdb-9923-fa6101699c09",
   "metadata": {},
   "source": [
    "The following cell will draw the network topology, for your reference. The interface name and addresses of each experiment interface will be shown on the drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a30b5-fade-4b89-98e1-9d757f0a0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_nets = [(n.get_name(), {'color': 'lavender'}) for n in slice.get_l2networks() ]\n",
    "l3_nets = [(n.get_name(), {'color': 'pink'}) for n in slice.get_l3networks() ]\n",
    "hosts   =   [(n.get_name(), {'color': 'lightblue'}) for n in slice.get_nodes()]\n",
    "nodes = l2_nets + l3_nets + hosts\n",
    "ifaces = [iface.toDict() for iface in slice.get_interfaces()]\n",
    "edges = [(iface['network'], iface['node'], \n",
    "          {'label': iface['physical_dev'] + '\\n' + iface['ip_addr'] + '\\n' + iface['mac']}) for iface in ifaces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1f8a5-cd7c-4784-a694-7c09f73e26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(nodes),len(nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in nodes], \n",
    "        node_size=[len(n[0])*400 for n in nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf46b8-310f-4893-af93-4389ec882afe",
   "metadata": {},
   "source": [
    "### Log into resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c2ac5-ee82-4bc8-b568-a423f4a6197d",
   "metadata": {},
   "source": [
    "Now, we are finally ready to log in to our resources over SSH! Run the following cells, and observe the table output - you will see an SSH command for each of the resources in your topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3e270-0d37-4f59-bf9a-591450653259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "slice_info = [{'Name': n.get_name(), 'SSH command': n.get_ssh_command()} for n in slice.get_nodes()]\n",
    "pd.DataFrame(slice_info).set_index('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26bfb9-6ada-45bf-86d4-e36519bd78f3",
   "metadata": {},
   "source": [
    "Now, you can open an SSH session on any of the resources as follows:\n",
    "\n",
    "-   in Jupyter, from the menu bar, use File \\> New \\> Terminal to open a new terminal.\n",
    "-   copy an SSH command from the table, and paste it into the terminal. (Note that each SSH command is a single line, even if the display wraps the text to a second line! When you copy and paste it, paste it all together.)\n",
    "\n",
    "You can repeat this process (open several terminals) to start a session on each resource. Each terminal session will have a tab in the Jupyter environment, so that you can easily switch between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b6b37-b634-4f4d-9776-ad69e6a3617c",
   "metadata": {},
   "source": [
    "### Execute Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19512d-dc7e-4860-a7af-bd280b318a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes and instances\n",
    "\n",
    "tx_L4S_node = slice.get_node(name=\"tx_L4S\")\n",
    "tx_legacy_node = slice.get_node(name=\"tx_legacy\")\n",
    "rx_L4S_node = slice.get_node(name=\"rx_L4S\")\n",
    "rx_legacy_node = slice.get_node(name=\"rx_legacy\")\n",
    "delay_node = slice.get_node(name=\"delay\")\n",
    "router_node = slice.get_node(name=\"router\")\n",
    "# interfaces\n",
    "\n",
    "tx_L4S_egress_iface  = tx_L4S_node.get_interface(network_name = \"net-tx\")\n",
    "tx_legacy_egress_iface  = tx_legacy_node.get_interface(network_name = \"net-tx\")\n",
    "\n",
    "delay_ingress_tx_iface  = delay_node.get_interface(network_name = \"net-tx\")\n",
    "delay_egress_iface  = delay_node.get_interface(network_name = \"net-delay-router\")\n",
    "delay_ingress_tx_name = delay_ingress_tx_iface.get_device_name()\n",
    "delay_egress_name = delay_egress_iface.get_device_name()\n",
    "\n",
    "router_ingress_iface  = router_node.get_interface(network_name = \"net-delay-router\")\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"net-rx\")\n",
    "router_egress_name  = router_egress_iface.get_device_name()\n",
    "\n",
    "\n",
    "rx_L4S_ingress_iface  = rx_L4S_node.get_interface(network_name = \"net-rx\")\n",
    "rx_legacy_ingress_iface  = rx_legacy_node.get_interface(network_name = \"net-rx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ba54b-155f-4b3f-8d42-36d0b0361504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full factorial experiment\n",
    "import itertools\n",
    "\n",
    "exp_factors = {\n",
    "    'n_bdp': [0.5, 2, 5, 10],  # n x bandwidth delay product\n",
    "    'btl_capacity': [100, 1000], #in Mbps #'btl_capacity': [100, 1000]\n",
    "    'base_rtt': [5, 10, 50, 100], # in ms #'base_rtt': [5, 10, 50, 100],\n",
    "    'aqm': ['FIFO', 'single_queue_FQ', 'Codel', 'FQ', 'FQ_Codel', 'DualPI2'],\n",
    "    'ecn_threshold': [1, 5, 20], # in ms #'ecn_threshold': [1, 5, 20]\n",
    "    'ecn_fallback': [0, 1],  #fallback algorithm, TCP Prague falls back to classic TCP when it detects single queue classic ECN bottleneck # 0: OFF, 1: ON  #'ecn_fallback': [0, 1]\n",
    "    'rx_L4S_ecn': [0,1,3],  # 0: noecn, 1: ecn, 3: accecn #'rx_L4S_ecn': [0, 1, 3]\n",
    "    'rx_legacy_ecn': [0,1],  # 0: noecn, 1: ecn #'rx_legacy_ecn': [0, 1]\n",
    "    'cc_tx_L4S': [\"prague\"],\n",
    "    'cc_tx_legacy': [\"cubic\", \"bbr\"],\n",
    "    'trial': [1,2,3,4,5] #'trial': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "flow_number_tx_L4S=1 #number of tx_L4S flows\n",
    "flow_number_tx_legacy=1 #number of tx_legacy flows\n",
    "\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "\n",
    "exp_lists = []\n",
    "\n",
    "seen_combinations = set()\n",
    "\n",
    "# Removing ECN factor from FIFO bottleneck because it does not support ECN\n",
    "# Removing the cases where ECN Threshold is less than or equal to the buffer size in time, these cases are not meaningful in practice\n",
    "\n",
    "for factor_l in factor_lists:\n",
    "    temp_dict = dict(zip(factor_names, factor_l))\n",
    "    if temp_dict['n_bdp'] * temp_dict['base_rtt'] >= temp_dict['ecn_threshold']:\n",
    "        if temp_dict['aqm'] == 'FIFO':\n",
    "            del temp_dict['ecn_threshold']\n",
    "        # Convert dict to a frozenset for set operations\n",
    "        fs = frozenset(temp_dict.items())\n",
    "    \n",
    "        if fs not in seen_combinations:\n",
    "            seen_combinations.add(fs)\n",
    "            exp_lists.append(temp_dict)\n",
    "\n",
    "data_dir_tx_L4S = slice_name + 'singlebottleneck'+\"-tx_L4S\"\n",
    "data_dir_tx_legacy = slice_name + 'singlebottleneck'+\"-tx_legacy\"\n",
    "\n",
    "print(\"Number of experiments:\",len(exp_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9fab13-28bd-4f57-a5e1-c20c9d364a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run experiments\n",
    "import time\n",
    "d = 60 #duration in seconds\n",
    "\n",
    "em = [delay_ingress_tx_name, delay_egress_name]\n",
    "\n",
    "for exp in exp_lists:\n",
    "\n",
    "    # check if we already ran this experiment\n",
    "    # (allow stop/resume)\n",
    "    name_tx_L4S=\"%s_%0.1f_%d_%d_%s_%s_%d_%d_%d_%d\" % (exp['cc_tx_L4S'],exp['n_bdp'], exp['btl_capacity'], exp['base_rtt'], exp['aqm'], str(exp.get('ecn_threshold', 'none')), exp['ecn_fallback'], exp['rx_L4S_ecn'], exp['rx_legacy_ecn'], exp['trial'])\n",
    "    name_tx_legacy=\"%s_%0.1f_%d_%d_%s_%s_%d_%d_%d_%d\" % (exp['cc_tx_legacy'],exp['n_bdp'], exp['btl_capacity'], exp['base_rtt'], exp['aqm'], str(exp.get('ecn_threshold', 'none')), exp['ecn_fallback'], exp['rx_L4S_ecn'], exp['rx_legacy_ecn'], exp['trial'])\n",
    "    \n",
    "    file_out_tx_L4S_json = name_tx_L4S+\"-result.json\"\n",
    "    stdout_tx_L4S_json, stderr_tx_L4S_json = tx_L4S_node.execute(\"ls \" + file_out_tx_L4S_json, quiet=True) \n",
    "    \n",
    "    file_out_tx_legacy_json =name_tx_legacy+\"-result.json\"\n",
    "    stdout_tx_legacy_json, stderr_tx_legacy_json = tx_legacy_node.execute(\"ls \" + file_out_tx_legacy_json, quiet=True) \n",
    "    \n",
    "\n",
    "    if len(stdout_tx_L4S_json) and len(stdout_tx_legacy_json):\n",
    "        print(\"Already have \" + name_tx_L4S + \" and \"+ name_tx_legacy + \", skipping\")\n",
    "\n",
    "    elif len(stderr_tx_L4S_json) or len(stderr_tx_legacy_json):\n",
    "        print(\"Running experiment to generate \" + name_tx_L4S + \" and \"+ name_tx_legacy) \n",
    "        \n",
    "        \n",
    "        tx_L4S_node.execute(\"sudo modprobe tcp_\" + exp['cc_tx_L4S'])\n",
    "        tx_L4S_node.execute(\"sudo sysctl -w net.ipv4.tcp_congestion_control=\" + exp['cc_tx_L4S'])\n",
    "        tx_L4S_node.execute(\"sudo sysctl -w net.ipv4.tcp_ecn=3\") # it is assumed that the L4S sender uses AccECN\n",
    "        \n",
    "        tx_legacy_node.execute(\"sudo modprobe tcp_\" + exp['cc_tx_legacy'])\n",
    "        tx_legacy_node.execute(\"sudo sysctl -w net.ipv4.tcp_congestion_control=\" + exp['cc_tx_legacy'])\n",
    "        tx_legacy_node.execute(\"sudo sysctl -w net.ipv4.tcp_ecn=1\") # it is assumed that the legacy sender uses Classic ECN\n",
    "        \n",
    "        # delay at emulator\n",
    "        for e in em:\n",
    "            cmds = \"sudo tc qdisc replace dev {iface} root netem delay {owd}ms limit 60000\".format(iface=e, owd=exp['base_rtt']/2)\n",
    "            delay_node.execute(cmds)\n",
    "        \n",
    "        # fixed values\n",
    "        btl_limit    = int(1000*exp['n_bdp']*exp['btl_capacity']*exp['base_rtt']/8) # limit of the bottleneck, n_bdp x BDP in bytes \n",
    "        packet_number=int(btl_limit/1500)+1\n",
    "        \n",
    "        \n",
    "        #ecn-fallback configuration\n",
    "               \n",
    "        commands = \"echo {value} | sudo tee /sys/module/tcp_prague/parameters/prague_ecn_fallback\".format(value=str(exp['ecn_fallback']))\n",
    "        tx_L4S_node.execute(commands)\n",
    "        \n",
    "        #receiver ecn configuration\n",
    "                \n",
    "        rx_L4S_node.execute(\"sudo sysctl -w net.ipv4.tcp_ecn={ecn_type}\".format(ecn_type=exp['rx_L4S_ecn']))\n",
    "        rx_legacy_node.execute(\"sudo sysctl -w net.ipv4.tcp_ecn={ecn_type}\".format(ecn_type=exp['rx_legacy_ecn']))\n",
    "        \n",
    "        #aqm type selection\n",
    "        cmds_prefix = '''\n",
    "            sudo tc qdisc del dev {iface} root\n",
    "            sudo tc qdisc replace dev {iface} root handle 1: htb default 3 \n",
    "            sudo tc class add dev {iface} parent 1: classid 1:3 htb rate {capacity}mbit \n",
    "            '''.format(iface=router_egress_name, capacity=exp['btl_capacity'], buffer=btl_limit)\n",
    "        \n",
    "        cmds_specific_initial = \"sudo tc qdisc replace dev {iface} parent 1:3 handle 3: \".format(iface=router_egress_name)\n",
    "        \n",
    "        cmds_specific = {\n",
    "        'FIFO': \"bfifo limit {buffer}\".format(buffer=btl_limit),\n",
    "        'single_queue_FQ': \"fq limit {packet_limit} flow_limit {packet_limit} orphan_mask 0 ce_threshold {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0)),\n",
    "        'Codel': \"codel limit {packet_limit} target {target}ms interval 100ms ecn ce_threshold {threshold}ms\".format(packet_limit=packet_number, target=exp['base_rtt']*exp['n_bdp'], threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ': \"fq limit {packet_limit} flow_limit {packet_limit} ce_threshold {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ_Codel': \"fq_codel limit {packet_limit} target {target}ms interval 100ms ecn ce_threshold {threshold}ms\".format(packet_limit=packet_number, target=exp['base_rtt']*exp['n_bdp'], threshold=exp.get('ecn_threshold', 0)),\n",
    "        'DualPI2': \"dualpi2 target {threshold}ms\".format(threshold=exp.get('ecn_threshold', 0))\n",
    "        }\n",
    "\n",
    "        cmds_aqm = {key: cmds_specific_initial + cmd for key, cmd in cmds_specific.items()}\n",
    "        \n",
    "        router_node.execute(cmds_prefix)\n",
    "        router_node.execute(cmds_aqm[ exp['aqm'] ])\n",
    "            \n",
    "        rx_L4S_node.execute(\"killall iperf3\")\n",
    "        rx_legacy_node.execute(\"killall iperf3\")\n",
    "        \n",
    "\n",
    "        #print(\"Starting experiment with {1} bdp {2} capacity {3} rtt {4} {5} thrshold {6} ecn_fallback {7} rx_L4S {8} rx_legacy for {duration} seconds\".format(duration=d, 1=exp['n_bdp'], 2=exp['btl_capacity'], 3=exp['base_rtt'], 4=exp['aqm'], 5=exp['ecn_threshold'], 6= exp['ecn_fallback'], 7=exp['rx_L4S_ecn'], 8=exp['rx_legacy_ecn']))\n",
    "        \n",
    "        rx_L4S_node.execute(\"iperf3 -s -1 -p 4000 -D\")\n",
    "        rx_legacy_node.execute(\"iperf3 -s -1 -p 5000 -D\")\n",
    "        \n",
    "        tx_L4S_node.execute_thread(\"sleep 1; iperf3 -c 10.0.5.100 -t {duration} -P {flows} -C {cc} -p 4000 -J > {flow}-result.json\".format(flow =name_tx_L4S, duration=d, flows=flow_number_tx_L4S, cc=exp['cc_tx_L4S']))\n",
    "        stdout, stderr = tx_legacy_node.execute(\"sleep 1; iperf3 -c 10.0.5.101 -t {duration} -P {flows} -C {cc} -p 5000 -J > {flow}-result.json\".format(flow =name_tx_legacy, duration=d, flows=flow_number_tx_legacy, cc=exp['cc_tx_legacy']))\n",
    "        time.sleep(3)  # time.sleep(1)\n",
    "        \n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33adbc37-7171-4c8b-9793-86319f87c892",
   "metadata": {},
   "source": [
    "### Analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136cf16-1dd7-48d7-bade-4105ee66a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_L4S_node.execute('mkdir '+data_dir_tx_L4S)\n",
    "\n",
    "tx_L4S_node.execute('mv *.json '+ data_dir_tx_L4S)\n",
    "tx_L4S_node.execute('tar -czvf '+data_dir_tx_L4S+ '.tgz ' +  data_dir_tx_L4S)\n",
    "\n",
    "\n",
    "tx_legacy_node.execute('mkdir '+data_dir_tx_legacy)\n",
    "\n",
    "tx_legacy_node.execute('mv *.json '+ data_dir_tx_legacy)      \n",
    "tx_legacy_node.execute('tar -czvf '+data_dir_tx_legacy+ '.tgz ' +  data_dir_tx_legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93728f4e-f1b3-4197-b7c7-d72062d56d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_L4S_node.upload_file(\"/home/fabric/work/analysis.py\", f\"/home/ubuntu/{data_dir_tx_L4S}/analysis.py\")\n",
    "tx_legacy_node.upload_file(\"/home/fabric/work/analysis.py\", f\"/home/ubuntu/{data_dir_tx_legacy}/analysis.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19669056-8d6a-4379-9cd3-fb81bd29664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_L4S_node.execute(f'python3 /home/ubuntu/{data_dir_tx_L4S}/analysis.py')\n",
    "tx_legacy_node.execute(f'python3 /home/ubuntu/{data_dir_tx_legacy}/analysis.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1c97d-8dc3-4238-90c5-22136d007416",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_L4S_node.download_file(\"/home/fabric/work/tput_tx_L4S.json\",f\"/home/ubuntu/{data_dir_tx_L4S}/throughput_data.json\")\n",
    "tx_L4S_node.download_file(\"/home/fabric/work/srtt_tx_L4S.json\",f\"/home/ubuntu/{data_dir_tx_L4S}/srtt_data.json\")\n",
    "\n",
    "tx_legacy_node.download_file(\"/home/fabric/work/tput_tx_legacy.json\",f\"/home/ubuntu/{data_dir_tx_legacy}/throughput_data.json\")\n",
    "tx_legacy_node.download_file(\"/home/fabric/work/srtt_tx_legacy.json\",f\"/home/ubuntu/{data_dir_tx_legacy}/srtt_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93edaf99-47fd-4dde-b284-7174a74bd85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Initialize empty variables\n",
    "throughput_data = {}\n",
    "srtt_data = {}\n",
    "\n",
    "# Directory containing JSON files\n",
    "data_directory = '/home/fabric/work/'\n",
    "\n",
    "# List of JSON files in the directory\n",
    "json_files = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
    "\n",
    "# Load data from each JSON file and update the variables\n",
    "for file_name in json_files:\n",
    "    file_path = os.path.join(data_directory, file_name)\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Check if the file contains throughput data or srtt data based on its name\n",
    "    if 'tput' in file_name:\n",
    "        throughput_data.update(data)\n",
    "    elif 'srtt' in file_name:\n",
    "        srtt_data.update(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740302a-15c2-4e5d-92bf-2e02911cc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8b0fb-60e7-4b70-96fe-d4322abe0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "srtt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc60faa-1efc-4f9a-940f-2ebbccd10c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_heatmap_for_fixed_btl(sorted_data_tx_L4S, sorted_data_tx_legacy):\n",
    "\n",
    "    # Initialize an empty dictionary to hold the heatmap data\n",
    "    heatmap_data = {}\n",
    "\n",
    "    # Loop through each rtt value under the fixed bottleneck\n",
    "    for yval in sorted_data_tx_L4S.keys():\n",
    "        # Loop through each AQM type\n",
    "        for aqm in sorted_data_tx_L4S[yval].keys():\n",
    "            prague_throughput = sorted_data_tx_L4S[yval][aqm]\n",
    "            cubic_throughput = sorted_data_tx_legacy[yval][aqm]\n",
    "            share = prague_throughput / (prague_throughput + cubic_throughput)\n",
    "\n",
    "            if yval not in heatmap_data:\n",
    "                heatmap_data[yval] = {}\n",
    "\n",
    "            heatmap_data[yval][aqm] = share\n",
    "\n",
    "    return heatmap_data\n",
    "\n",
    "def plot_heatmap_for_rtt(sorted_data_tx_L4S, sorted_data_tx_legacy):\n",
    "    # Initialize an empty dictionary to hold the heatmap data\n",
    "    heatmap_data = {}\n",
    "\n",
    "    # Loop through each rtt value under the fixed bottleneck\n",
    "    for yval in sorted_data_tx_L4S.keys():\n",
    "        # Loop through each AQM type\n",
    "        for aqm in sorted_data_tx_L4S[yval].keys():\n",
    "            prague_rtt = sorted_data_tx_L4S[yval][aqm]\n",
    "            cubic_rtt = sorted_data_tx_legacy[yval][aqm]\n",
    "            cubic_relative_diff = (cubic_rtt - prague_rtt) / cubic_rtt\n",
    "\n",
    "            if yval not in heatmap_data:\n",
    "                heatmap_data[yval] = {}\n",
    "\n",
    "            heatmap_data[yval][aqm] = cubic_relative_diff\n",
    "\n",
    "    return heatmap_data\n",
    "\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b322e4-5089-43aa-b508-61446a9516cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shutil, tarfile\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "import itertools\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from itertools import product\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "specified_params1 = {\n",
    "    'btl_capacity': [100],\n",
    "    #'n_bdp': [0.5, 2, 5, 10],\n",
    "    'base_rtt': [5, 10, 50], \n",
    "    'ecn_threshold': [1, 5],\n",
    "    'ecn_fallback': [0], \n",
    "    'rx_L4S_ecn': [2],\n",
    "    'rx_legacy_ecn': [1],\n",
    "    # 'aqm': 'FIFO'\n",
    "\n",
    "}\n",
    "\n",
    "keys = specified_params1.keys() \n",
    "values = (specified_params1[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in product(*values)]\n",
    "\n",
    "exp_factors['btl_capacity'] \n",
    "exp_factors['base_rtt']  \n",
    "\n",
    "factor_x = 'aqm'  # choose which parameter you want to observe\n",
    "factor_y = 'n_bdp'  # choose which parameter you want to observe\n",
    "\n",
    "# Create nested dictionaries to store data by btl_capacity and base_rtt\n",
    "\n",
    "fig1, axes1 = plt.subplots(2, 3, figsize=(53, 30))\n",
    "fig2, axes2 = plt.subplots(2, 3, figsize=(53, 30)) # Adjust the figsize as needed\n",
    "\n",
    "for index, i in enumerate(combinations):\n",
    "    specified_params=i\n",
    "    relevant_data_tx_L4S = {}\n",
    "    relevant_data_tx_legacy = {}\n",
    "    relevant_srtt_data_tx_L4S = {}\n",
    "    relevant_srtt_data_tx_legacy = {}\n",
    "    \n",
    "    for exp in exp_lists:\n",
    "        is_relevant = all(\n",
    "            (k == 'ecn_threshold' and (v == exp.get(k) or exp.get(k) is None)) or\n",
    "            (k != 'ecn_threshold' and v == exp.get(k)) for k, v in specified_params.items()\n",
    "        )\n",
    "    \n",
    "        if is_relevant:\n",
    "            btl = exp['btl_capacity']\n",
    "            rtt = exp['base_rtt']\n",
    "    \n",
    "            name_tx_L4S = \"%s_%0.1f_%d_%d_%s_%s_%d_%d_%d_%d\" % (\n",
    "                exp['cc_tx_L4S'], exp['n_bdp'], btl, rtt, exp['aqm'], str(exp.get('ecn_threshold', 'none')),\n",
    "                exp['ecn_fallback'],\n",
    "                exp['rx_L4S_ecn'], exp['rx_legacy_ecn'], exp['trial'])\n",
    "            name_tx_legacy = \"%s_%0.1f_%d_%d_%s_%s_%d_%d_%d_%d\" % (\n",
    "                exp['cc_tx_legacy'], exp['n_bdp'], btl, rtt, exp['aqm'], str(exp.get('ecn_threshold', 'none')),\n",
    "                exp['ecn_fallback'],\n",
    "                exp['rx_L4S_ecn'], exp['rx_legacy_ecn'], exp['trial'])\n",
    "    \n",
    "            xval = exp[factor_x]\n",
    "            yval= exp[factor_y]\n",
    "            # Update relevant_data_tx_L4S\n",
    "            if name_tx_L4S in throughput_data:\n",
    "                if yval not in relevant_data_tx_L4S:\n",
    "                    relevant_data_tx_L4S[yval] = {}\n",
    "                if xval not in relevant_data_tx_L4S[yval]:\n",
    "                    relevant_data_tx_L4S[yval][xval] = []\n",
    "                relevant_data_tx_L4S[yval][xval].append(throughput_data[name_tx_L4S])\n",
    "    \n",
    "            # Update relevant_data_tx_legacy\n",
    "            if name_tx_legacy in throughput_data:\n",
    "                if yval not in relevant_data_tx_legacy:\n",
    "                    relevant_data_tx_legacy[yval] = {}\n",
    "                if xval not in relevant_data_tx_legacy[yval]:\n",
    "                    relevant_data_tx_legacy[yval][xval] = []\n",
    "                relevant_data_tx_legacy[yval][xval].append(throughput_data[name_tx_legacy])\n",
    "    \n",
    "            # Update relevant_srtt_data_tx_L4S\n",
    "            if name_tx_L4S in srtt_data:\n",
    "                if yval not in relevant_srtt_data_tx_L4S:\n",
    "                    relevant_srtt_data_tx_L4S[yval] = {}\n",
    "                if xval not in relevant_srtt_data_tx_L4S[yval]:\n",
    "                    relevant_srtt_data_tx_L4S[yval][xval] = []\n",
    "                relevant_srtt_data_tx_L4S[yval][xval].append(srtt_data[name_tx_L4S]-rtt)\n",
    "    \n",
    "            # Update relevant_srtt_data_tx_legacy\n",
    "            if name_tx_legacy in srtt_data:\n",
    "                if yval not in relevant_srtt_data_tx_legacy:\n",
    "                    relevant_srtt_data_tx_legacy[yval] = {}\n",
    "                if xval not in relevant_srtt_data_tx_legacy[yval]:\n",
    "                    relevant_srtt_data_tx_legacy[yval][xval] = []\n",
    "                relevant_srtt_data_tx_legacy[yval][xval].append(srtt_data[name_tx_legacy]-rtt)\n",
    "\n",
    "    # Average the throughputs for tx_L4S\n",
    "    for yval, xval_data in relevant_data_tx_L4S.items():\n",
    "        for xval, throughputs in xval_data.items():\n",
    "            relevant_data_tx_L4S[yval][xval] = np.mean(throughputs)\n",
    "    \n",
    "    # Average the throughputs for tx_legacy\n",
    "    for yval, xval_data in relevant_data_tx_legacy.items():\n",
    "        for xval, throughputs in xval_data.items():\n",
    "            relevant_data_tx_legacy[yval][xval] = np.mean(throughputs)\n",
    "    \n",
    "    # Average the srtts for tx_L4S\n",
    "    for yval, xval_data in relevant_srtt_data_tx_L4S.items():\n",
    "        for xval, srtts in xval_data.items():\n",
    "            relevant_srtt_data_tx_L4S[yval][xval] = np.mean(srtts) \n",
    "    \n",
    "    # Average the srtts for tx_legacy\n",
    "    for yval, xval_data in relevant_srtt_data_tx_legacy.items():\n",
    "        for xval, srtts in xval_data.items():\n",
    "            relevant_srtt_data_tx_legacy[yval][xval] = np.mean(srtts)\n",
    "    \n",
    "    # Sort and get values for each btl and rtt combination\n",
    "    sorted_throughputs_tx_L4S = {}\n",
    "    sorted_throughputs_tx_legacy = {}\n",
    "    sorted_rtts_tx_L4S = {}\n",
    "    sorted_rtts_tx_legacy = {}\n",
    "    \n",
    "    for yval in sorted(relevant_data_tx_L4S.keys()):\n",
    "        sorted_throughputs_tx_L4S[yval] = {}\n",
    "        sorted_rtts_tx_L4S[yval] = {}\n",
    "        \n",
    "        for xval in sorted(relevant_data_tx_L4S[yval].keys()):\n",
    "            sorted_throughputs_tx_L4S[yval][xval] = relevant_data_tx_L4S[yval].get(xval, None)\n",
    "            sorted_rtts_tx_L4S[yval][xval] = relevant_srtt_data_tx_L4S[yval].get(xval, None)\n",
    "    \n",
    "    \n",
    "    for yval in sorted(relevant_data_tx_legacy.keys()):\n",
    "        sorted_throughputs_tx_legacy[yval] = {}\n",
    "        sorted_rtts_tx_legacy[yval] = {}\n",
    "        \n",
    "        for xval in sorted(relevant_data_tx_legacy[yval].keys()):\n",
    "            sorted_throughputs_tx_legacy[yval][xval] = relevant_data_tx_legacy[yval].get(xval, None)\n",
    "            sorted_rtts_tx_legacy[yval][xval] = relevant_srtt_data_tx_legacy[yval].get(xval, None)\n",
    "    \n",
    "    \n",
    "    title_map = {\n",
    "    'btl_capacity': lambda: f\"{specified_params['btl_capacity']}Mbps-\",\n",
    "    'n_bdp': lambda: f\"{specified_params['n_bdp']}BDP-\",\n",
    "    'base_rtt': lambda: f\"{specified_params['base_rtt']}ms RTT-\",\n",
    "    'ecn_threshold': lambda: f\"ECN Threshold = {specified_params['ecn_threshold']}ms -\",\n",
    "    'rx_L4S_ecn': lambda: f\"ServerA ECN={specified_params['rx_L4S_ecn']}-\",\n",
    "    'rx_legacy_ecn': lambda: f\"ServerB ECN={specified_params['rx_legacy_ecn']}-\",\n",
    "    'ecn_fallback': lambda: f\"ECN Fallback={specified_params['ecn_fallback']}\"\n",
    "     }\n",
    "    \n",
    "\n",
    "    \n",
    "    desired_order = ['FIFO', 'single_queue_FQ', 'Codel', 'FQ', 'FQ_Codel', 'DualPI2']\n",
    "    #desired_order = ['FIFO', 'single_queue_FQ']\n",
    "    \n",
    "    # Convert the dictionary to a Pandas DataFrame\n",
    "    df = pd.DataFrame(plot_heatmap_for_fixed_btl(sorted_throughputs_tx_L4S, sorted_throughputs_tx_legacy))\n",
    "    df = df.reindex(desired_order)\n",
    "    df=df.rename(index={'FQ_Codel': 'FQ Codel'})\n",
    "    df=df.rename(index={'single_queue_FQ': 'Single  \\nQueue FQ'})\n",
    "    df_rtt = pd.DataFrame(plot_heatmap_for_rtt(sorted_rtts_tx_L4S, sorted_rtts_tx_legacy))\n",
    "    df_rtt = df_rtt.reindex(desired_order)\n",
    "    df_rtt=df_rtt.rename(index={'FQ_Codel': 'FQ Codel'})\n",
    "    df_rtt=df_rtt.rename(index={'single_queue_FQ': 'Single  \\nQueue FQ'})\n",
    "    df_masked = np.ma.masked_invalid(df)\n",
    "    df_masked_rtt = np.ma.masked_invalid(df_rtt)\n",
    "\n",
    "    \n",
    "    dynamic_title = ''.join(val() for key, val in title_map.items() if key != factor_y)\n",
    "    cmap = plt.cm.coolwarm  # Start with the coolwarm colormap\n",
    "    cmap.set_bad(color='black')  # Set the color for masked values (None/NaN)\n",
    "    \n",
    "    #Plot the heatmap\n",
    "    #plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    ax1 = axes1[index % 2, index // 2] \n",
    "    #ax1 = axes1[index]\n",
    "    sns.heatmap(df, annot=True, cmap=cmap, cbar_kws={'label': 'Prague Throughput Share'}, annot_kws={\"size\": 50}, vmin=0, vmax=1, ax=ax1, cbar=False)\n",
    "    ax1.set_title(dynamic_title, fontsize=20)\n",
    "    ax1.set_xlabel('Buffer Size (n x BDP)', fontsize=20)\n",
    "    ax1.set_ylabel(\"AQM Types\", fontsize=20)\n",
    "    ax1.set_yticklabels(ax1.get_yticklabels(), fontsize=10) # Adjust for y-axis labels\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), fontsize=20) # Adjust for x-axis labels\n",
    "    \n",
    "    ax2 = axes2[index % 2, index // 2] \n",
    "    #ax2 = axes2[index] \n",
    "    sns.heatmap(df_rtt, annot=True, cmap=cmap, cbar_kws={'label': 'Cubic Relative Queuing Delay'}, annot_kws={\"size\": 50},  vmin=-1, vmax=1, ax=ax2, cbar=False)\n",
    "    ax2.set_title(dynamic_title, fontsize=20)\n",
    "    #ax2.set_xlabel(factor_y, fontsize=40)\n",
    "    ax2.set_xlabel('Buffer Size (n x BDP)', fontsize=20)\n",
    "    ax2.set_ylabel(\"AQM Types\", fontsize=20)\n",
    "    ax2.set_yticklabels(ax2.get_yticklabels(), fontsize=20) # Adjust for y-axis labels\n",
    "    ax2.set_xticklabels(ax2.get_xticklabels(), fontsize=20) # Adjust for x-axis labels\n",
    "    \n",
    "    \n",
    "plt.figure(fig1.number)\n",
    "fig1.suptitle('100 Mbps - Server A ECN: AccECN - Server B ECN: Classic ECN - ECN Fallback: OFF', fontsize=45) \n",
    "#fig1.subplots_adjust(hspace=0.15)  # Adjust the vertical spacing\n",
    "cbar_ax = fig1.add_axes([0.92, 0.15, 0.02, 0.7])  # x-position, y-position, width, height\n",
    "cbar=fig1.colorbar(ax1.collections[0], cax=cbar_ax)\n",
    "cbar.set_label('Prague Throughput Share', size=40)  \n",
    "cbar.ax.tick_params(labelsize=35)\n",
    "plt.tight_layout(rect=[0, 0.01, 0.9, 0.98], pad=1.08, h_pad=1.5, w_pad=1.08)\n",
    "plt.savefig('/home/fabric/work/throughput.png', dpi=100)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(fig2.number)\n",
    "fig2.suptitle('100 Mbps - Server A ECN: AccECN - Server B ECN: Classic ECN - ECN Fallback: OFF', fontsize=45) \n",
    "cbar_ax = fig2.add_axes([0.92, 0.15, 0.02, 0.7])  # x-position, y-position, width, height\n",
    "cbar=fig2.colorbar(ax2.collections[0], cax=cbar_ax)\n",
    "cbar.set_label('Cubic Relative Queuing Delay', size=40)  \n",
    "cbar.ax.tick_params(labelsize=35)\n",
    "plt.tight_layout(rect=[0, 0.01, 0.9, 0.98], pad=1.08, h_pad=1.5, w_pad=1.08)\n",
    "plt.savefig('/home/fabric/work/relativedelay.png', dpi=100)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
